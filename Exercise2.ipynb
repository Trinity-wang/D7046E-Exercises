{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Learning Machines\n",
    "## Exercise 2 - Training and Validation\n",
    "This exercise builds on the first one. The aim of the first exercise was that you should get familiar with Jupyter notebooks and the PyTorch framework by training your first neural network.\n",
    "\n",
    "In this exercise, you have the task to properly validate the classifier and improve the training procedure to get a more reliable (and justifiable) score.\n",
    "\n",
    "However, before starting that task, you should complete a more basic exercise with perceptrons to understand how units in artificial neural networks are evaluated and how changes of the parameters can make a neuron detect a specific input pattern.\n",
    "\n",
    "In this exercise you will need to:\n",
    "    1. Define perceptrons by hand that predict the digits of a 7-segment display.\n",
    "    2. Implement a way to validate the performance of an MNIST classifier.\n",
    "    3. Rewrite the training protocol (the code) to avoid overfitting.\n",
    "    4. Produce a graph of the training and validation performance of the model over the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-segment prediction\n",
    "\n",
    "A 7-segment display [https://en.wikipedia.org/wiki/Seven-segment_display] can be used to display the different digits by turning the different segments (A,B,C,D,E,F) on or off. Your task is to design ten different perceptrons that recognizes the ten different digits (0,1,2,3, ... ,9) represented by a 7-segment display. The input to each perceptron will be a vector {A,B,C,D,E,F} where A is 1 if segment A is turned on and 0 otherwise (and the same for all the other segments).\n",
    "\n",
    "This means that for each digit you should create a perceptron which output is larger than 0 for that digit and below 0 for all other digits. You don't need to consider non-digit cases.\n",
    "\n",
    "![Seven Segment Display](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/7_Segment_Display_with_Labeled_Segments.svg/225px-7_Segment_Display_with_Labeled_Segments.svg.png)\n",
    "\n",
    "For this task it is recommended to use numpy rather than PyTorch.\n",
    "\n",
    "After completing this exercise you should understand how an artificial neural network unit (like the perceptron) produces one scalar output from multiple input values, and how the parameter values determine the relation between output and input values (amplitudes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE CODE FOR 10 DIFFERENT PERCEPTRONS THAT EACH RECOGNIZES A SPECIFIC DIGIT\n",
    "\n",
    "# Example perceptron\n",
    "# Note that this perceptron is missing something and can therefore not solve the given task\n",
    "# Fix that something and then create ten different neurons to solve recognize each digit\n",
    "\n",
    "# The input, since all 7 segments are currently 1 this input would correspond to an \"8\"\n",
    "\n",
    "def perceptron(x, w):\n",
    "    return 1.0 if w.dot(x) >= 1.0 else 0.0\n",
    "\n",
    "    \n",
    "def result(x):\n",
    "    return [\n",
    "        perceptron(x, numpy.array([1/6,1/6,1/6,1/6,1/6,1/6,-1])),\n",
    "        perceptron(x, numpy.array([-1,1/2,1/2,-1,-1,-1,-1])),\n",
    "        perceptron(x, numpy.array([1/5,1/5,-1,1/5,1/5,-1,1/5])),\n",
    "        perceptron(x, numpy.array([1/5,1/5,1/5,1/5,-1,-1,1/5])),\n",
    "        perceptron(x, numpy.array([-1, 1/4, 1/4, -1, -1, 1/4, 1/4])),\n",
    "        perceptron(x, numpy.array([1/5,-1,1/5,1/5,-1,1/5,1/5])),\n",
    "        perceptron(x, numpy.array([1/6,-1,1/6,1/6,1/6,1/6,1/6])),\n",
    "        perceptron(x, numpy.array([1/3,1/3,1/3,-1,-1,-1,-1])),\n",
    "        perceptron(x, numpy.array([1/7,1/7,1/7,1/7,1/7,1/7,1/7])),\n",
    "        perceptron(x, numpy.array([1/6,1/6,1/6,1/6,-1,1/6,1/6]))\n",
    "    ]\n",
    "\n",
    "assert result(numpy.array([1,1,1,1,1,1,0])) == [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([0,1,1,0,0,0,0])) == [0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([1,1,0,1,1,0,1])) == [0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([1,1,1,1,0,0,1])) == [0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([0,1,1,0,0,1,1])) == [0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([1,0,1,1,0,1,1])) == [0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([1,0,1,1,1,1,1])) == [0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0]\n",
    "assert result(numpy.array([1,1,1,0,0,0,0])) == [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]\n",
    "assert result(numpy.array([1,1,1,1,1,1,1])) == [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]\n",
    "assert result(numpy.array([1,1,1,1,0,1,1])) == [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many mini-batches will the dataset be split into\n",
    "batch_size = 1000\n",
    "\n",
    "# Create a loader for the training set\n",
    "mnist_train = datasets.MNIST('./', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create a loader for the validation set\n",
    "mnist_validation = datasets.MNIST('./', train=False, download=True, transform=transforms.ToTensor())\n",
    "validation_loader = DataLoader(mnist_validation, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def plot_digit(data):\n",
    "    # Transfrom the images into an appropriate shape for displaying\n",
    "    data = data.view(28,28)\n",
    "    plt.imshow(data, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "images, labels = next(iter(train_loader))\n",
    "plot_digit(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network\n",
    "\n",
    "Like in the previous exercise you'll need to implement an artificial neural network, select an optimizer, and select a loss function that results in low validation and training errors.\n",
    "\n",
    "The units of the resulting artificial neural network functions much like the perceptrons that you designed in the first part of this exercise, with the differences that other activation functions are considered; many units are connected; and that there are many more parameters that are optimized numerically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code initializes the neural network\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(784, 784),\n",
    "    nn.ReLU(),\n",
    "    #nn.Linear(784, 784),\n",
    "    #nn.ReLU(),\n",
    "    nn.Linear(784, 784),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(784, 10)\n",
    ")\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.5)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# An Embedding layer used for turning int into one-hot (0 -> [1,0,0,0,0,0,0,0,0,0], 5 -> [0,0,0,0,0,1,0,0,0,0])\n",
    "to_onehot = nn.Embedding(10, 10) \n",
    "to_onehot.weight.data = torch.eye(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "From here on forward you will need to edit the code in order to complete the exercise.\n",
    "You have been provided with a simple training code and no validation code at all. The goal of the exercise is to implement a validation procedure to evaluate how well the network learns to generalize, plot the performance of the network on the validation set over a number of training epochs, and then to improve the training code to minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(iterable):\n",
    "    nb = 0\n",
    "    success = 0\n",
    "    for batch_nr, (images, labels) in enumerate(iterable):\n",
    "        images = images.view(-1,784)\n",
    "        prediction = network(images)\n",
    "        for p,l in zip(prediction,labels):\n",
    "            guess = torch.argmax(p, dim=-1)\n",
    "            nb += 1\n",
    "            if guess.item()==l.item():\n",
    "                success+=1\n",
    "    return success/nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decide the number of epochs to train for (one epoch is one complete run-through of the data)\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# Create a list to keep track of how the loss changes\n",
    "losses = []\n",
    "training_score = []\n",
    "validation_score = []\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # A variable for containing the sum of all batch losses for this epoch\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # For each batch\n",
    "    for batch_nr, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Extract the labels and turn them into one-hot representation (note: not all loss functions needs this)\n",
    "        labels = to_onehot(labels)\n",
    "        \n",
    "        # Reshape the images to a single vector (28*28 = 784)\n",
    "        images = images.view(-1,784)\n",
    "        \n",
    "        # Predict for each digit in the batch whatclass they belong to\n",
    "        prediction = network(images)\n",
    "        \n",
    "        # Calculate the loss of the prediction by comparing to the expected output\n",
    "        loss = loss_function(prediction, labels)\n",
    "        \n",
    "        # Backpropogate the loss through the network to find the gradients of all parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters along their gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Clear stored gradient values\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Add the loss to the total epoch loss (item() turns a PyTorch scalar into a normal Python datatype)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #Print the epoch, batch, and loss\n",
    "        print(\n",
    "            '\\rEpoch {} [{}/{}] - Loss: {}'.format(\n",
    "                epoch+1, batch_nr+1, len(train_loader), loss\n",
    "            ),\n",
    "            end=''\n",
    "        )\n",
    "    \n",
    "    #Append the epoch loss to the list of losses\n",
    "    losses.append(epoch_loss)\n",
    "    training_score.append(validate(train_loader))\n",
    "    validation_score.append(validate(validation_loader))\n",
    "    print(\"Training score is {} and validation is {}\".format(training_score[-1],validation_score[-1]))\n",
    "\n",
    "# Plot the training loss per epoch\n",
    "plt.plot(range(1,epochs+1),losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1,epochs+1),validation_score, 'g')\n",
    "plt.plot(range(1,epochs+1),training_score, 'r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
